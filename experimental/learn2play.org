* L2P Hearthstone
** Part 1
*** Hearthstone or Not?

    The objective is to take videos and classify whether they are Hearthstone
    or not.

**** Annotating
     :PROPERTIES:
     :header-args: :tangle hs_annotate.py :comments both :noweb yes
     :END:

     The first step is necessarily annotation. I have a bunch of videos and
     need to note the exact frames at which the transition from Hearthstone to
     Not (or visa-versa) occurs.

     This is a tool to annotate videos with binary labels.

     #+begin_src python
import numpy as np
import cv2
import sys
from functools import partial
     #+end_src

     #+name: load_video
     #+begin_src python
def load_video(filename):
    cap = cv2.VideoCapture(filename)
    return cap, current_frame(cap), num_frames(cap)
     #+end_src

     #+name: meta
     #+begin_src python
def num_frames(cap):
    return int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))

def current_frame(cap):
    return int(cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES))
     #+end_src

     #+name: seek
     #+begin_src python
def seek(cap, pos):
    if pos > num_frames(cap):
        raise Exception

    cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, pos)
     #+end_src

     #+begin_src python
def main():
    cap, position, max_position = load_video(sys.argv[1])

    window_name = 'frame'  # winning an award for 'most creative name' for sure
    cv2.namedWindow(window_name)
    cv2.createTrackbar('frame_bar', window_name,
                       position, max_position,
                       partial(seek, cap))

    partition_points = []
    advance = False
    save = True

    ret, frame = cap.read()

    try:
        while cap.isOpened() and current_frame(cap) < num_frames(cap):
            if advance:
                ret, frame = cap.read()
                cv2.setTrackbarPos('frame_bar', window_name, current_frame(cap))

            cv2.imshow(window_name, frame)

            key = cv2.waitKey(25) & 0xFF

            if key == 27:  # ESC
                save = False
                break
            elif key == ord('.'):
                ret, frame = cap.read()
                cv2.setTrackbarPos('frame_bar', window_name, current_frame(cap))
            elif not advance and key == ord('t'):
                index = current_frame(cap)
                if index in partition_points:
                    partition_points.remove(index)
                else:
                    partition_points.append(index)
                    partition_points.sort()
                    print(partition_points)
            elif key == ord(' '):
                advance = not advance

        cap.release()
        cv2.destroyAllWindows()

    except Exception as e:
        print(e)

    finally:
        if save:
            with open(sys.argv[1] + '.partitions', 'w') as dest:
                dest.write(','.join(map(str, partition_points)))

if __name__ == "__main__":
    main()
     #+end_src



**** Classifying

***** Extracting Frames

      Gonna use a generator for frames from a video because =cv2= doesn't have
      a nice iterable for them.

      #+name: frame-gen
      #+begin_src python
def frames(cap):
    while True:
        ret, frame = cap.read()
        if ret:
            yield frame
        else:
            break
      #+end_src

      This function creates the cv2 cap object as well as the list of partition points.
      #+name: cap-open
      #+begin_src python
def cap_open(path):
    with open(path + '.partitions') as f:
        return cv2.VideoCapture(path), f.read().split(',')
      #+end_src

***** Extracting Features

      I am using SURF features. Because why not.

      #+name: task:features
      #+begin_src python
def features(surf, frame):
    kp, desc = surf.detectAndCompute(frame, None)
    return desc

import scipy.misc
def resize(frame, size=(256, 256)):
    return scipy.misc.imresize(frame, size)

class Features(luigi.Task):
    video = luigi.Parameter()
    rate = luigi.IntParameter(default=10)  # 1 in $rate frames are used
    upright = luigi.BooleanParameter(default=True)
    hessianThreshold = luigi.IntParameter(default=5000)

    def output(self):
        path = self.video + '_surf_{rate}_{upright}{hessian}.npz'.format(
            upright='upright_' if self.upright else '',
            hessian=self.hessianThreshold,
            rate=self.rate,
        )
        return luigi.LocalTarget(path)

    def run(self):
        <<frame-gen>>

        cap = cv2.VideoCapture(self.video)
        surf = cv2.SURF(self.hessianThreshold, upright=self.upright)

        video_features = {str(index): features(surf, frame)
                          for index, frame in enumerate(frames(cap))
                          if index % self.rate == 0}
        # some frames produce None for their descriptor, don't know why
        video_features = {k: v for k, v in video_features.items()
                          if v is not None}

        with self.output().open('w') as out:
            np.savez_compressed(out, **video_features)
      #+end_src

***** Building Vocabulary

      I am using a Bag of Visual Words model with k-means clustering to develop
      a vocabulary. The =Vocabulary= task encodes the construction of a
      vocabulary on a set of videos with a number of words.

      #+name: task:vocabulary
      #+begin_src python
class Vocabulary(luigi.Task):
    num_words = luigi.IntParameter(default=300)
    num_videos = luigi.IntParameter(default=10)
    rate = luigi.IntParameter(default=100)
    seed = luigi.IntParameter(default=None, significant=False)

    def output(self):
        path = 'training/{words}_{videos}.npz'.format(
            words=self.num_words,
            videos=self.num_videos
        )
        return luigi.LocalTarget(path)

    def run(self):
        from glob import glob
        from random import seed, shuffle
        paths = glob('twitch/Hearthstone/*/*/raws/*.flv')
        seed(self.seed)
        shuffle(paths)

        all_features = []
        feats = yield [Features(video=path,rate=self.rate) for path in paths[:self.num_videos]]
        for feat in feats:
            with feat.open('r') as f:
                features = dict(np.load(f).items()).values()
                all_features += features

        all_features = np.vstack(all_features)

        compactness, labels, centers = cv2.kmeans(
            all_features, self.num_words,
            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,1000,1.0),
            10, 0)

        with self.output().open('w') as out:
            np.savez_compressed(
                out,
                compactness=compactness,
                labels=labels,
                centers=centers
            )
      #+end_src

***** Constructing the SVM Model

      #+name: task:svm-hs?
      #+begin_src python
class HearthstoneModel(luigi.Task):
    rate = luigi.IntParameter(default=100)

    def output(self):
        return luigi.LocalTarget('training/hearthstone_model.xml')

    def run(self):
        def response(partitions, frame_num):
            hearthstone = False
            for partition in partitions:
                if frame_num < partition:
                    return (1 if hearthstone else -1)
                hearthstone = not hearthstone
            return (1 if hearthstone else -1)

        def histogram(centers, feat):
            h = np.zeros((len(centers),), dtype='float32')
            for f in feat:
                dist = np.linalg.norm(centers - f, axis=1)
                h[dist.argmax()] += 1
            return h / np.linalg.norm(h)

        from glob import glob
        paths = glob('twitch/Hearthstone/*/*/raws/*.flv.partitions')

        vocab_out = yield Vocabulary(rate=self.rate)
        with vocab_out.open('r') as f:
            npz = np.load(f)
            centers = npz['centers']

        features = yield [Features(video=path.rstrip('.partitions'), rate=self.rate)
                          for path in paths]

        svm = cv2.SVM()
        trainData = []
        responses = []
        for path, feat in zip(paths, features):
            with open(path, 'r') as f:
                p_raw = f.read()
                if p_raw:
                    partitions = [int(p) for p in p_raw.split(',')]
                else:
                    partitions = []

            with feat.open('r') as f:
                features = np.load(f).items()
                for frame_num, feat in features:
                    frame_num = int(frame_num)
                    trainDatum = histogram(centers, feat)
                    resp = response(partitions, frame_num)
                    trainData.append(trainDatum)
                    responses.append(resp)

        trainData = np.vstack(trainData)
        responses = np.vstack(responses)
        np.savez_compressed('svm_data.npz', trainData=trainData, responses=responses)
        print(responses.shape)
        svm.train_auto(
            trainData, responses,
            None, None,  # everything is interesting
            {"svm_type": cv2.SVM_C_SVC,
             "kernel_type": cv2.SVM_LINEAR,},
            10,
        )
        svm.save(self.output().path)
      #+end_src
***** Putting it Together

      :HIDDEN:
      #+begin_src python
import cv2
import numpy as np


<<features-frame>>


<<frame-gen>>


<<cap-open>>


<<model-input-gen>>


<<train-fn>>


def main(dest, paths):
    svm = cv2.SVM()
    for path in paths:
        svm = train(svm, path)
    svm.save(dest)


if __name__ == '__main__':
    import argparse
    import sys
    parser = argparse.ArgumentParser()
    parser.add_argument('dest')
    parser.add_argument('paths', nargs=argparse.REMAINDER)

    args = parser.parse_args()

    if len(args.paths) is 0:
        paths = (p.strip() for p in sys.stdin)
        main(args.dest, paths)
    else:
        main(args.dest, args.paths)
      #+end_src
      :END:

      #+begin_src python :tangle learn2play.py :comments both :noweb yes
import luigi
import cPickle as pickle
import cv2
import numpy as np
import sys


<<task:features>>


<<task:vocabulary>>


<<task:svm-hs?>>

if __name__ == "__main__":
    luigi.run()
      #+end_src


** Random Utils
*** OpenCV Key Printer

    #+begin_src python :tangle keyprint.py
import cv2
import numpy as np

im = np.zeros((256,256))
cv2.imshow('frame', im)
while True:
    key = cv2.waitKey() & 0xFF
    print(key)
    if key == 27:
        break

cv2.destroyAllWindows()
    #+end_src
